{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **REGRESSION MODELS FOR HOUSE PRICES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **INITIALIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fetch engineered train and test data\n",
    "train = pd.read_csv('train_engineered.csv')\n",
    "test = pd.read_csv('test_engineered.csv')\n",
    "outcomes = pd.read_csv('outcomes.csv')\n",
    "y_train = np.asarray(outcomes['SalePrice'].values)\n",
    "train_id = train['Id']; test_id = test['Id']\n",
    "del train['Id']\n",
    "del test['Id']\n",
    "\n",
    "# feature selection\n",
    "features_selected =['AllSF', 'OverallQual', 'AllFlrsSF', '1stFlr_2ndFlr_Sf', 'GrLivArea',\n",
    "                    'All_Liv_SF', 'ExterQual', 'TotalBath', 'KitchenQual', 'GarageCars',\n",
    "                    'OverallGrade', '1stFlrSF', 'ExterGrade', 'YearBuilt', 'FullBath',\n",
    "                    'YearRemodAdd', 'TotRmsAbvGrd', 'FireplaceScore', 'FireplaceQu',\n",
    "                    'Foundation_PConc', 'BsmtQual', 'GarageArea', 'Fireplaces',\n",
    "                    'GarageScore', 'HeatingQC', 'OpenPorchSF', 'TotalBsmtSF',\n",
    "                    'KitchenScore', 'MasVnrArea', 'GarageFinish_Fin', 'GarageType_Attchd',\n",
    "                    'LotArea', 'HasMasVnr', 'LotFrontage', 'GarageGrade', 'GarageQual',\n",
    "                    'GarageCond', 'Neighborhood_NridgHt', 'CentralAir_Y', 'WoodDeckSF',\n",
    "                    'Exterior2nd_VinylSd', 'Exterior1st_VinylSd', 'BsmtExposure',\n",
    "                    'SaleType_New', 'GarageYrBlt', 'BoughtOffPlan', 'SaleCondition_Partial',\n",
    "                    'HalfBath', 'MasVnrType_Stone', 'BsmtFinType1', 'RecentRemodel', 'lat',\n",
    "                    'IsElectricalSBrkr', 'Electrical_SBrkr', 'PavedDrive', 'HasWoodDeck',\n",
    "                    'GarageType_No', 'GarageFinish_No', 'Foundation_CBlock', 'MSZoning_RM',\n",
    "                    'CentralAir_N', 'MasVnrType_None', 'GarageType_Detchd', \n",
    "                    'IsGarageDetached', 'GarageFinish_Unf', 'HasOpenPorch']\n",
    "\n",
    "# split features observations for train and forecast\n",
    "train = train[features_selected]; test = test[features_selected]\n",
    "#X = np.asarray(train[features_selected])\n",
    "#X_forecast = np.asarray(test[features_selected])\n",
    "#print(X.shape, y_train.shape, X_forecast.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CROSS-VALIDATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross-validation with shuffling\n",
    "n_folds = 5\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse = np.sqrt(-cross_val_score(model, train.values, y_train, \n",
    "                                    scoring='neg_mean_squared_error', cv=kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODELS** from https://www.kaggle.com/pavel1988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model selection\n",
    "# LASSO regression made robust to outliers with RobustScaler\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha=0.0003, random_state=1))\n",
    "# elastic net regression\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0003, l1_ratio=0.9, random_state=3))\n",
    "# kernel ridge regression\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "# gradient boosting regression with huber loss that makes it robust to outliers\n",
    "GBoost = GradientBoostingRegressor(n_estimators=5000, learning_rate=0.05, max_depth=4,\n",
    "                                  max_features='sqrt', min_samples_leaf=15, \n",
    "                                   min_samples_split=10, loss='huber', random_state=5)\n",
    "# xgboost\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, learning_rate=0.05,\n",
    "                            max_depth=3, min_child_weight=1.7817, n_estimators=2200,\n",
    "                            reg_alpha=0.4640, reg_lambda=0.8571, subsample=0.5213,\n",
    "                            silent=1, random_state=7, nthread=-1)\n",
    "# light gbm\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression', num_leaves=5, learning_rate=0.05,\n",
    "                             n_estimators=720, max_bin=55, bagging_fraction=0.8,\n",
    "                             bagging_freq=5, feature_fraction=0.2319, \n",
    "                             feature_fraction_sed=9, bagging_seed=9, min_data_in_leaf=6,\n",
    "                             min_sum_hessian_in_leaf=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **BASE MODELS SCORES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 0.1119 (0.0057)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the cross-validation rmsle error\n",
    "score = rmsle_cv(lasso)\n",
    "print('\\nLasso score: {:.4f} ({:.4f})\\n'.format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ENet score: 0.1119 (0.0057)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(ENet)\n",
    "print('\\nENet score: {:.4f} ({:.4f})\\n'.format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KRR score: 0.1499 (0.0213)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(KRR)\n",
    "print('\\nKRR score: {:.4f} ({:.4f})\\n'.format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GBoost score: 0.1140 (0.0065)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(GBoost)\n",
    "print('\\nGBoost score: {:.4f} ({:.4f})\\n'.format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb score: 0.1134 (0.0065)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_xgb)\n",
    "print('\\nxgb score: {:.4f} ({:.4f})\\n'.format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lgb score: 0.1130 (0.0073)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_lgb)\n",
    "print('\\nlgb score: {:.4f} ({:.4f})\\n'.format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **STACKING MODELS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AVERAGING BASE MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write a class to encapsulate model and reuse\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    # define clones of the original models to fit in the data\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        # train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    # make predictions for cloned models and average predictions\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([model.predict(X) for model in self.models_])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06127002603441056, tolerance: 0.018911334381783333\n",
      "  positive)\n",
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14336315475093286, tolerance: 0.017996952084854287\n",
      "  positive)\n",
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05794905455444521, tolerance: 0.01837208344628373\n",
      "  positive)\n",
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.049997024266270174, tolerance: 0.019012728260948037\n",
      "  positive)\n",
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.031873248780117436, tolerance: 0.019012728260948037\n",
      "  positive)\n",
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07354215623719718, tolerance: 0.018809511234293343\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged base models score: 0.1170 (0.0066))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# average the base models ENet, GBoost, KRR and Lasso\n",
    "averaged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))\n",
    "score = rmsle_cv(averaged_models)\n",
    "print('Averaged base models score: {:.4f} ({:.4f}))\\n'.format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **COMPLEX STACKING: ADDING A META-MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ADD A META-MODEL ON AVERAGED BASE MODELS AND USE THE OUT-OF-FOLDS PREDICTIONS OF BASE MODELS\n",
    "# TO TRAIN OUR META-MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. split train set into 2 disjoint sets (train and holdout)\n",
    "# 2. train several base models on the first part (train)\n",
    "# 3. test the models from 2. on the second part (holdout)\n",
    "# 4. use the predictions from 3. (out-of-fold predictions) as inputs,\n",
    "#    and the correct outcomes (target variable) as output to train a\n",
    "#    higher level learner called meta-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STACKING AVERAGED MODELS CLASS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# again, write a class to encapsulate\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "    # fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        # train cloned base models then create out-of-fold predictions needed\n",
    "        # to train the cloned meta model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "        # train cloned meta-model using the out_of_fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "        \n",
    "    #make predictions of all base models on the test data and take averages as meta-features\n",
    "    # for the final prediction done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "                np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "                for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3727667249196571, tolerance: 0.015352122603876524\n",
      "  positive)\n",
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2157750957327087, tolerance: 0.01402953240838431\n",
      "  positive)\n",
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.539866287984216, tolerance: 0.01465232268185746\n",
      "  positive)\n",
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01771003889789391, tolerance: 0.014383423640949165\n",
      "  positive)\n",
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020252994700650007, tolerance: 0.014445958492010684\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: 0.1071 (0.0060)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use the same models: average Enet, KRR and GBoost, then add lasso as meta-model\n",
    "stacked_averaged_models = StackingAveragedModels(base_models=(ENet, GBoost, KRR),\n",
    "                                                meta_model=lasso)\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print('Stacking Averaged models score: {:.4f} ({:.4f})\\n'.format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ENSEMBLING STACKEDREGRESSOR, XGBOOST AND LIGHTGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluation function\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03146276188238417, tolerance: 0.01857942630719395\n",
      "  positive)\n",
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02212144415809192, tolerance: 0.01884056867573906\n",
      "  positive)\n",
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.034248440827585824, tolerance: 0.01861071819533334\n",
      "  positive)\n",
      "/home/kumo/venv/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020143087721535835, tolerance: 0.019083266172540594\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07814376127966635\n"
     ]
    }
   ],
   "source": [
    "# stacked regressor\n",
    "stacked_averaged_models.fit(train.values, y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(train.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\n",
    "print(rmsle(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08284055511870037\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "model_xgb.fit(train, y_train)\n",
    "xgb_train_pred = model_xgb.predict(train)\n",
    "xgb_pred = np.expm1(model_xgb.predict(test))\n",
    "print(rmsle(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07883216458873454\n"
     ]
    }
   ],
   "source": [
    "model_lgb.fit(train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(train)\n",
    "lgb_pred = np.expm1(model_lgb.predict(test.values))\n",
    "print(rmsle(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score on train data:\n",
      "0.07699122182532601\n"
     ]
    }
   ],
   "source": [
    "# combined scoring\n",
    "'''RMSE on the entire Train data when averaging'''\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y_train, stacked_train_pred*0.70 + xgb_train_pred*0.15 + lgb_train_pred*0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensemble prediction\n",
    "ensemble = stacked_pred*0.70+ xgb_pred*0.15 + lgb_pred*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>120097.273523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>161615.711620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>184195.472198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>193073.539693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>186013.338494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1466</td>\n",
       "      <td>173034.543152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1467</td>\n",
       "      <td>175605.371582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1468</td>\n",
       "      <td>166429.277457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1469</td>\n",
       "      <td>191506.117446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1470</td>\n",
       "      <td>121455.587709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1471</td>\n",
       "      <td>200083.591783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1472</td>\n",
       "      <td>96229.837541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1473</td>\n",
       "      <td>97191.723393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1474</td>\n",
       "      <td>150941.354550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1475</td>\n",
       "      <td>117311.114025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1476</td>\n",
       "      <td>385047.171215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1477</td>\n",
       "      <td>252791.203104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1478</td>\n",
       "      <td>300908.925432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1479</td>\n",
       "      <td>286492.882020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1480</td>\n",
       "      <td>519023.682375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1481</td>\n",
       "      <td>350040.827923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1482</td>\n",
       "      <td>212378.841622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1483</td>\n",
       "      <td>174291.961588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1484</td>\n",
       "      <td>173498.032572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1485</td>\n",
       "      <td>182180.747857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1486</td>\n",
       "      <td>196380.022526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1487</td>\n",
       "      <td>320747.873567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1488</td>\n",
       "      <td>229731.645672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1489</td>\n",
       "      <td>198940.727575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1490</td>\n",
       "      <td>210940.954534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id      SalePrice\n",
       "0   1461  120097.273523\n",
       "1   1462  161615.711620\n",
       "2   1463  184195.472198\n",
       "3   1464  193073.539693\n",
       "4   1465  186013.338494\n",
       "5   1466  173034.543152\n",
       "6   1467  175605.371582\n",
       "7   1468  166429.277457\n",
       "8   1469  191506.117446\n",
       "9   1470  121455.587709\n",
       "10  1471  200083.591783\n",
       "11  1472   96229.837541\n",
       "12  1473   97191.723393\n",
       "13  1474  150941.354550\n",
       "14  1475  117311.114025\n",
       "15  1476  385047.171215\n",
       "16  1477  252791.203104\n",
       "17  1478  300908.925432\n",
       "18  1479  286492.882020\n",
       "19  1480  519023.682375\n",
       "20  1481  350040.827923\n",
       "21  1482  212378.841622\n",
       "22  1483  174291.961588\n",
       "23  1484  173498.032572\n",
       "24  1485  182180.747857\n",
       "25  1486  196380.022526\n",
       "26  1487  320747.873567\n",
       "27  1488  229731.645672\n",
       "28  1489  198940.727575\n",
       "29  1490  210940.954534"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare for submission\n",
    "sub = pd.DataFrame()\n",
    "sub['Id']= test_id\n",
    "sub['SalePrice'] = ensemble\n",
    "sub.to_csv('submission_regression.csv', index=False)\n",
    "sub.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
