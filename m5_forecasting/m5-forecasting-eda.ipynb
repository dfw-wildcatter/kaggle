{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EXPLORATORY DATA ANALYSIS FOR M5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **INITIALIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required packages\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('bmh')\n",
    "%matplotlib inline\n",
    "\n",
    "#import seaborn as sns\n",
    "#color = sns.color_palette()\n",
    "#sns.set_style('darkgrid')\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "import gc\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings from sklearn and seaborn\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn\n",
    "\n",
    "# pandas output format\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar.csv\n",
      "M5-Competitors-Guide-Final-10-March-2020.odt\n",
      "m5-forecasting-eda (copy 1).ipynb\n",
      "m5-forecasting-eda.ipynb\n",
      "m5-forecasting-eda.py\n",
      "sales_train_validation.csv\n",
      "sample_submission.csv\n",
      "sell_prices.csv\n",
      "SGB-m5-forecasting.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check files available\n",
    "from subprocess import check_output\n",
    "print(check_output(['ls', os.getcwd()]).decode('utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXPLORATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_dtypes = {'event_name_1': 'category', 'event_name_2': 'category', \n",
    "              'event_type_1': 'category', 'event_type_2': 'category',\n",
    "              'weekday': 'category', 'wm_yr_wk': 'int16', 'wday': 'int16',\n",
    "              'month': 'int16', 'year': 'int16', 'snap_CA': 'float32', \n",
    "              'snap_TX': 'float32', 'snap_WI': 'float32'}\n",
    "price_dtypes = {'store_id': 'category', 'item_id': 'category', 'wm_yr_wk': 'int16',\n",
    "               'sell_price': 'float32'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2016, 4, 25, 0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters for constructing time series\n",
    "h = 28 # forecast horizon\n",
    "max_lags = 57\n",
    "tr_last = 1913 # last training observation\n",
    "fday = datetime(2016, 4, 25) # forecast start date\n",
    "fday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct time series\n",
    "def create_df(is_train = True, nrows = None, first_day = 1200):\n",
    "    prices = pd.read_csv('sell_prices.csv', dtype = price_dtypes)\n",
    "    for col, col_dtype in price_dtypes.items():\n",
    "        if col_dtype == 'category':\n",
    "            prices[col] = prices[col].cat.codes.astype('int16')\n",
    "            prices[col] -= prices[col].min() # scaling\n",
    "    cal = pd.read_csv('calendar.csv', dtype = cal_dtypes)\n",
    "    cal['date'] = pd.to_datetime(cal['date'])\n",
    "    for col, col_dtype in cal_dtypes.items():\n",
    "        if col_dtype == 'category':\n",
    "            cal[col] = cal[col].cat.codes.astype('int16')\n",
    "            cal[col] -= cal[col].min()\n",
    "    \n",
    "    start_day = max(1 if is_train else tr_last - max_lags, first_day)\n",
    "    numcols = [f'd_{day}' for day in range(start_day, tr_last+1)] #sales data rolling window\n",
    "    catcols = ['id', 'item_id', 'dept_id', 'store_id', 'cat_id', 'state_id']\n",
    "    dtype = {numcol: 'float32' for numcol in numcols}\n",
    "    dtype.update({col: 'category' for col in catcols if col != 'id'})\n",
    "    df = pd.read_csv('sales_train_validation.csv', nrows = nrows, \n",
    "                     usecols = catcols + numcols, dtype = dtype)\n",
    "    for col in catcols:\n",
    "        if col != 'id':\n",
    "            df[col] = df[col].cat.codes.astype('int16')\n",
    "            df[col] -= df[col].min()\n",
    "    if not is_train:\n",
    "        for day in range(tr_last + 1, tr_last + 28 + 1):\n",
    "            df[f'd_{day}'] = np.nan\n",
    "    df = pd.melt(df, \n",
    "                 id_vars = catcols,\n",
    "                 value_vars = [col for col in df.columns if col.startswith('d_')], # numeric\n",
    "                 var_name = 'd', # day\n",
    "                 value_name = 'sales')\n",
    "    df = df.merge(cal, on='d', copy = False)\n",
    "    df = df.merge(prices, on = ['store_id', 'item_id', 'wm_yr_wk'], copy=False)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create forecast series\n",
    "def create_fea(df):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f'lag_{lag}' for lag in lags]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        df[lag_col] = df[['id', 'sales']].groupby('id')['sales'].shift(lag)\n",
    "        \n",
    "    wins = [7, 28] # windows\n",
    "    for win in wins:\n",
    "        for lag, lag_col in zip(lags, lag_cols):\n",
    "            df[f'rmean_{lag}_{win}'] = df[['id', lag_col]].groupby('id')[lag_col].transform(lambda x: x.rolling(win).mean())\n",
    "    \n",
    "    date_features = {\n",
    "        'wday': 'weekday',\n",
    "        'week': 'weekofyear',\n",
    "        'month': 'month',\n",
    "        'quarter': 'quarter',\n",
    "        'year': 'year',\n",
    "        'mday': 'day'}\n",
    "    \n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in df.columns:\n",
    "            df[date_feat_name] = df[date_feat_name].astype('int16')\n",
    "        else:\n",
    "            df[date_feat_name] = getattr(df['date'].dt, date_feat_func).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 s, sys: 3.54 s, total: 36.2 s\n",
      "Wall time: 37.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37960593, 22)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = create_df(is_train=True, first_day = 500) #skip days to save on memory\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37960593 entries, 0 to 37960592\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   id            object        \n",
      " 1   item_id       int16         \n",
      " 2   dept_id       int16         \n",
      " 3   store_id      int16         \n",
      " 4   cat_id        int16         \n",
      " 5   state_id      int16         \n",
      " 6   d             object        \n",
      " 7   sales         float32       \n",
      " 8   date          datetime64[ns]\n",
      " 9   wm_yr_wk      int16         \n",
      " 10  weekday       int16         \n",
      " 11  wday          int16         \n",
      " 12  month         int16         \n",
      " 13  year          int16         \n",
      " 14  event_name_1  int16         \n",
      " 15  event_type_1  int16         \n",
      " 16  event_name_2  int16         \n",
      " 17  event_type_2  int16         \n",
      " 18  snap_CA       float32       \n",
      " 19  snap_TX       float32       \n",
      " 20  snap_WI       float32       \n",
      " 21  sell_price    float32       \n",
      "dtypes: datetime64[ns](1), float32(5), int16(14), object(2)\n",
      "memory usage: 2.8+ GB\n"
     ]
    }
   ],
   "source": [
    "#df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 25s, sys: 9.61 s, total: 3min 35s\n",
      "Wall time: 3min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37960593, 31)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "create_fea(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37960593 entries, 0 to 37960592\n",
      "Data columns (total 31 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   id            object        \n",
      " 1   item_id       int16         \n",
      " 2   dept_id       int16         \n",
      " 3   store_id      int16         \n",
      " 4   cat_id        int16         \n",
      " 5   state_id      int16         \n",
      " 6   d             object        \n",
      " 7   sales         float32       \n",
      " 8   date          datetime64[ns]\n",
      " 9   wm_yr_wk      int16         \n",
      " 10  weekday       int16         \n",
      " 11  wday          int16         \n",
      " 12  month         int16         \n",
      " 13  year          int16         \n",
      " 14  event_name_1  int16         \n",
      " 15  event_type_1  int16         \n",
      " 16  event_name_2  int16         \n",
      " 17  event_type_2  int16         \n",
      " 18  snap_CA       float32       \n",
      " 19  snap_TX       float32       \n",
      " 20  snap_WI       float32       \n",
      " 21  sell_price    float32       \n",
      " 22  lag_7         float32       \n",
      " 23  lag_28        float32       \n",
      " 24  rmean_7_7     float32       \n",
      " 25  rmean_28_7    float32       \n",
      " 26  rmean_7_28    float32       \n",
      " 27  rmean_28_28   float32       \n",
      " 28  week          int16         \n",
      " 29  quarter       int16         \n",
      " 30  mday          int16         \n",
      "dtypes: datetime64[ns](1), float32(11), int16(17), object(2)\n",
      "memory usage: 3.9+ GB\n"
     ]
    }
   ],
   "source": [
    "#df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nans\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "cat_feats = ['item_id', 'dept_id', 'store_id', 'cat_id', 'state_id'] + ['event_name_1', 'event_name_2', 'event_type_1', 'event_type_2']\n",
    "useless_cols = ['id', 'date', 'sales', 'd', 'wm_yr_wk', 'weekday']\n",
    "train_cols = df.columns[~df.columns.isin(useless_cols)]\n",
    "X_train = df[train_cols]\n",
    "y_train = df['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.random.seed(777)\n",
    "fake_valid_inds = np.random.choice(X_train.index.values, 2_000_000, replace=False)\n",
    "train_inds = np.setdiff1d(X_train.index.values, fake_valid_inds)\n",
    "train_data = lgb.Dataset(X_train.loc[train_inds], label = y_train.loc[train_inds], \n",
    "                        categorical_feature = cat_feats, free_raw_data=False)\n",
    "fake_valid_data = lgb.Dataset(X_train.loc[fake_valid_inds], label = y_train.loc[fake_valid_inds],\n",
    "                            categorical_feature = cat_feats, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, X_train, y_train, fake_valid_inds, train_inds: gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective' : 'poisson',\n",
    "    'metric' : 'rmse',\n",
    "    'force_row_wise': True,\n",
    "    'learning_rate': 0.075,\n",
    "    'sub_row': 0.75, \n",
    "    'baggin_freq': 1,\n",
    "    'lambda_12': 0.1,\n",
    "    'metric': ['rmse'],\n",
    "    'verbosity': 1,\n",
    "    'num_iterations': 1200,\n",
    "    'num_leaves': 128,\n",
    "    'min_data_in_leaf': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% time\n",
    "\n",
    "m_lgb = lgb.train(params, train_data, valid_sets = [fake_valid_data], verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18,4)\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "lgb.plot_importance(m_lgb, max_num_features=50, height=0.8, ax=ax)\n",
    "ax.grid(False)\n",
    "plt.title('LightGBM - Feature Importance', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lgb.save_model('model.lgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features_for_test(dt, day):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f'lag_{lag}' for lag in lags]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        df.loc[df.date == day, lag_col] = \\\n",
    "            df.loc[df.date == day-timedelta(days=lag), 'sales'].values\n",
    "\n",
    "    windows = [7,28]\n",
    "    for window in windows:\n",
    "        for lag in lags:\n",
    "            df_window = df[(df.date <= day-timedelta(days=lag)) \n",
    "                           & (df.date > day-timedelta(days=lag+window))]\n",
    "            df_window_grouped = df_window.groupby('id').agg({'sales':'mean'}).reindex(df.loc[df.date==day,'id'])\n",
    "            df.loc[df.date == day, f'rmean_{lag}_{window}'] = df_window_grouped.sales.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_features_for_test(df):\n",
    "    date_features = {\n",
    "        'wday': 'weekday',\n",
    "        'week': 'weekofyear',\n",
    "        'month': 'month',\n",
    "        'quarter': 'quarter',\n",
    "        'year': 'year',\n",
    "        'mday': 'day'}\n",
    "    \n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in df.columns:\n",
    "            df[date_feat_name] = df[date_feat_name].astype('int16')\n",
    "        else:\n",
    "            df[date_feat_name] = getattr(df['date'].dt, date_feat_func).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% time\n",
    "\n",
    "alphas = [1.028, 1.023, 1.018]\n",
    "weights = [1/len(alphas)]*len(alphas)\n",
    "\n",
    "te0 = create_df(False)\n",
    "create_date_features_for_test(te0)\n",
    "\n",
    "for icount, (alpha, weight) in enumerate(zip(alphas, weights)):\n",
    "    te = te0.copy()\n",
    "    cols =[f'F{i}' for i in range(1, 29)]\n",
    "    \n",
    "    for tdelta in range(0, 28):\n",
    "        day = fday + timedelta(days=tdelta)\n",
    "        print(tdelta, day.date())\n",
    "        tst = te[(te.date >= day - timedelta(days=max_lags)) & (te.date <= day)].copy()\n",
    "        create_lag_features_for_test(tst, day)\n",
    "        tst = tst.loc[tst.date == day, train_cols]\n",
    "        te.loc[te.date == day, 'sales'] = \\\n",
    "            alpha * m_lgb.predict(tst) # magic multiplier by kyakovlev\n",
    "    \n",
    "    te_sub = te.loc[te.date >= fday, ['id', 'sales']].copy()\n",
    "    te_sub['F'] = [f'F{rank}' for rank in te_sub.groupby('id')['id'].cumcount()+1]\n",
    "    te_sub = te_sub.set_index(['id', 'F']).unstack()['sales'][cols].reset_index()\n",
    "    te_sub.fillna(0., inplace=True)\n",
    "    te_sub.sort_values('id', inplace=True)\n",
    "    te_sub.reset_index(drop=True, inplace=True)\n",
    "    te_sub.to_csv(f'submission_{icount}.csv', index=False)\n",
    "    if icount == 0:\n",
    "        sub = te_sub\n",
    "        sub[cols] *= weight\n",
    "    else:\n",
    "        sub[cols] += te_sub[cols]*weight\n",
    "    print(icount, alpha, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.id.nunique(), sub['id'].str.contains('validation$').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = sub.copy()\n",
    "sub2['id'] = sub2['id'].str.replace('validation$', 'evaluation')\n",
    "sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "sub.to_csv('submission_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
